# -*- coding: utf-8 -*-
"""Model_uj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v43awZo3bWPOSiEoF9tN-C78Hn_b0hXR
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

class Model(nn.Module):
    def __init__(self, class_num= 4):
        super(Model, self).__init__()

        self.data_net = nn.Sequential(
            self.conv(in_channels=3, out_channels=16, kernel_size=5, stride=1),
            self.conv(in_channels=16, out_channels=32, kernel_size=7, stride=1),
            self.conv(in_channels=32, out_channels=64, kernel_size=5, stride=1),
        )

        self.red_net = nn.Sequential(
            self.conv(in_channels=3, out_channels=16, kernel_size=5, stride=1),
            self.conv(in_channels=16, out_channels=32, kernel_size=7, stride=1),
            self.conv(in_channels=32, out_channels=64, kernel_size=5, stride=1),
        )

        self.combine_net = nn.Sequential(
            self.conv(in_channels=128, out_channels=64, kernel_size=3, stride = 1),
            self.conv(in_channels=64, out_channels=32, kernel_size=3, stride = 1),
        )

        self.fc_layer = nn.Sequential(
            nn.Flatten(),
            self.fc(in_features = 5 * 5 * 32, out_features = 120),
            self.fc(in_features = 120, out_features = 84),
            self.fc(in_features = 84, out_features = class_num, activation=nn.Sigmoid()),
        )


    def forward(self, data, red):
        d_out = self.data_net(data)
        r_out = self.red_net(red)
        combine = torch.cat((d_out, r_out), dim=1)
        
        out = self.combine_net(combine)
        out = self.fc_layer(out)

        return out


    def conv(self, in_channels, out_channels, kernel_size, stride, conv_padding=0, BN=True, pooling=True, activation=nn.ReLU()):
        modules = []

        modules.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=conv_padding))
        if pooling:
            modules.append(nn.MaxPool2d(kernel_size=2, stride=2))
        if BN:
            modules.append(nn.BatchNorm2d(num_features=out_channels))
        if activation is not None:
            modules.append(activation)

        return nn.Sequential(*modules) 

    def fc(self, in_features, out_features, activation=nn.ReLU()):
        modules = []

        modules.append(nn.Linear(in_features=in_features, out_features=out_features))
        if activation is not None:
            modules.append(activation)
        
        return nn.Sequential(*modules)

"""
lica_model = Model(class_num=4)
temp_tensor_1 = torch.randn(1, 3, 256, 256)
temp_tensor_2 = torch.randn(1, 3, 256, 256)
out_data= lica_model(temp_tensor_1,temp_tensor_2)

print(out_data.shape, out_data)
print(torch.argmax(out_data, dim=1))
"""